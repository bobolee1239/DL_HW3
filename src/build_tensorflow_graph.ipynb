{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CNN_Architecture:\n",
    "    def __init__(self, numFilters, filterSize, strides, toPadding, \n",
    "                useReLU, numInputChannels, maxPoolingSize=None):\n",
    "        self.numFilters = numFilters\n",
    "        self.filterSize = filterSize\n",
    "        self.strides = strides\n",
    "        self.maxPoolingSize = maxPoolingSize\n",
    "        self.toPadding = toPadding\n",
    "        self.useReLU = useReLU\n",
    "        self.numInputChannels = numInputChannels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def new_weights(shape):\n",
    "    stdev = 0.1\n",
    "    w = tf.Variable(tf.random_uniform(shape=shape, minval = -stdev, maxval = stdev))\n",
    "    return w\n",
    "\n",
    "def new_biases(length):\n",
    "    stdev = 0.1\n",
    "    b = tf.Variable(tf.random_uniform(shape=[length], minval = -stdev, maxval = stdev))\n",
    "    return b\n",
    "\n",
    "def new_convLayer(inputLayer, cnnArchitecture, name = \"conv2d\", stdev = 0.01):\n",
    "    with tf.variable_scope(name):\n",
    "        paddingAlgorithm = 'SAME' if cnnArchitecture.toPadding else 'VALID'\n",
    "        filterSpec = list(cnnArchitecture.filterSize) + [cnnArchitecture.numInputChannels, \n",
    "                                                         cnnArchitecture.numFilters]\n",
    "        weights = tf.get_variable('w', filterSpec, \n",
    "                          initializer = tf.truncated_normal_initializer(stddev=stdev))\n",
    "        biases = tf.get_variable('bias', [cnnArchitecture.numFilters], \n",
    "                                  initializer = tf.constant_initializer(0.0))\n",
    "\n",
    "        convLayer = tf.nn.conv2d(input = inputLayer, \n",
    "                                 filter = weights, \n",
    "                                 strides = [1, cnnArchitecture.strides, \n",
    "                                            cnnArchitecture.strides, 1], \n",
    "                                 padding = paddingAlgorithm)\n",
    "        convLayer = convLayer + biases\n",
    "\n",
    "        if cnnArchitecture.maxPoolingSize:\n",
    "            steps = [1, cnnArchitecture.maxPoolingSize[0], \n",
    "                        cnnArchitecture.maxPoolingSize[1], 1]\n",
    "            convLayer = tf.nn.max_pool(value=convLayer, \n",
    "                                       ksize=steps, \n",
    "                                       strides = steps, \n",
    "                                       padding = paddingAlgorithm)\n",
    "        if cnnArchitecture.useReLU: convLayer = tf.nn.relu(convLayer)\n",
    "\n",
    "        return convLayer, weights\n",
    "\n",
    "def new_dconvLayer(inputLayer, cnnArchitecture, outputShape, \n",
    "                   name = \"dconv2d\", stdev = 0.01):\n",
    "    with tf.variable_scope(name):\n",
    "        paddingAlgorithm = 'SAME' if cnnArchitecture.toPadding else 'VALID'\n",
    "        filterSpec = list(cnnArchitecture.filterSize) + [cnnArchitecture.numInputChannels, \n",
    "                                                         cnnArchitecture.numFilters]\n",
    "        weights = tf.get_variable('w', filterSpec, \n",
    "                          initializer = tf.truncated_normal_initializer(stddev=stdev))\n",
    "        biases = tf.get_variable('bias', [outputShape[-1]], \n",
    "                                  initializer = tf.constant_initializer(0.0))\n",
    "\n",
    "        convLayer = tf.nn.conv2d_transpose(inputLayer, \n",
    "                                           output_shape=outputShape,\n",
    "                                           filter = weights, \n",
    "                                           strides = [1, cnnArchitecture.strides, \n",
    "                                                        cnnArchitecture.strides, 1], \n",
    "                                           padding = paddingAlgorithm)\n",
    "        convLayer = convLayer + biases\n",
    "\n",
    "#         if cnnArchitecture.maxPoolingSize:\n",
    "#             steps = [1, cnnArchitecture.maxPoolingSize[0], \n",
    "#                         cnnArchitecture.maxPoolingSize[1], 1]\n",
    "#             convLayer = tf.nn.max_pool(value=convLayer, \n",
    "#                                        ksize=steps, \n",
    "#                                        strides = steps, \n",
    "#                                        padding = paddingAlgorithm)\n",
    "        if cnnArchitecture.useReLU: convLayer = tf.nn.relu(convLayer)\n",
    "\n",
    "        return convLayer\n",
    "\n",
    "def flattenLayer(layer):\n",
    "    \"\"\"\n",
    "    [width, height, numFilters]\n",
    "    \"\"\"\n",
    "    shape = layer.get_shape()\n",
    "    # shape = [#imgs, height, width, numFilters]\n",
    "    numAttrs = shape[1:].num_elements()\n",
    "    \n",
    "    layer_flat = tf.reshape(layer, shape=[-1, numAttrs])\n",
    "    return layer_flat, numAttrs\n",
    "\n",
    "def new_fcLayer(inputLayer, inputChannels, outputChannels, useReLU=True, \n",
    "                name=\"fc\", stdev=0.01):\n",
    "    with tf.variable_scope(name):\n",
    "        weights = tf.get_variable('w', shape=[inputChannels, outputChannels], \n",
    "                                initializer=tf.random_normal_initializer(stddev=stdev))\n",
    "        biases = tf.get_variable('bias', shape=[outputChannels], \n",
    "                                 initializer=tf.constant_initializer(0.0))\n",
    "        layer = tf.matmul(inputLayer, weights) + biases\n",
    "        if useReLU:\n",
    "            layer = tf.nn.relu(layer)\n",
    "        return layer\n",
    "    \n",
    "def bn(x, is_training, scope):\n",
    "    return tf.contrib.layers.batch_norm(x,\n",
    "                                        decay=0.9,\n",
    "                                        updates_collections=None,\n",
    "                                        epsilon=1e-5,\n",
    "                                        scale=True,\n",
    "                                        is_training=is_training,\n",
    "                                        scope=scope)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "if __name__ == '__main__':\n",
    "    cnnArchitecture = CNN_Architecture(numFilters = 20, \n",
    "                                       filterSize = (3, 3), \n",
    "                                       strides = 2, \n",
    "                                       toPadding = False, \n",
    "                                       useReLU = True,\n",
    "                                       numInputChannels = 200,\n",
    "                                       maxPoolingSize=(2, 2))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
