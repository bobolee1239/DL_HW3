{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#!/usr/bin/env python3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import numpy as np \n",
    "import time \n",
    "from datetime import timedelta\n",
    "import tensorflow as tf\n",
    "from readImages import *\n",
    "from build_tensorflow_graph import *\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#\n",
    "## ---------- DCGAN Architecture ----------\n",
    "#\n",
    "\n",
    "numFilters1 = 32\n",
    "numFilters2 = 64\n",
    "numFilters3 = 128\n",
    "numFilters4 = 256\n",
    "\n",
    "# Convolution Layer 1\n",
    "cnnArchitecture1 = CNN_Architecture(numFilters = numFilters1, \n",
    "                                    filterSize = (4, 4), \n",
    "                                    strides = 1, \n",
    "                                    toPadding = True, \n",
    "                                    useReLU = True, \n",
    "                                    numInputChannels = 3, \n",
    "                                    maxPoolingSize=(2, 2))\n",
    "\n",
    "dcnnArchitecture1 = CNN_Architecture(numFilters = 3, \n",
    "                                    filterSize = (4, 4), \n",
    "                                    strides = 1, \n",
    "                                    toPadding = True, \n",
    "                                    useReLU = False, \n",
    "                                    numInputChannels = numFilters1, \n",
    "                                    maxPoolingSize=(2, 2))\n",
    "\n",
    "# Convolution Layer 2\n",
    "cnnArchitecture2 = CNN_Architecture(numFilters = numFilters2, \n",
    "                                    filterSize = (3, 3), \n",
    "                                    strides = 1, \n",
    "                                    toPadding = True, \n",
    "                                    useReLU = True, \n",
    "                                    numInputChannels = numFilters1, \n",
    "                                    maxPoolingSize=(2, 2))\n",
    "dcnnArchitecture2 = CNN_Architecture(numFilters = numFilters1, \n",
    "                                    filterSize = (3, 3), \n",
    "                                    strides = 1, \n",
    "                                    toPadding = True, \n",
    "                                    useReLU = True, \n",
    "                                    numInputChannels = numFilters2, \n",
    "                                    maxPoolingSize=(2, 2))\n",
    "\n",
    "# Convolution Layer 3\n",
    "cnnArchitecture3 = CNN_Architecture(numFilters = numFilters3,\n",
    "                                    filterSize = (3, 3), \n",
    "                                    strides = 1, \n",
    "                                    toPadding = True, \n",
    "                                    useReLU = True, \n",
    "                                    numInputChannels = numFilters2, \n",
    "                                    maxPoolingSize=(2, 2))\n",
    "dcnnArchitecture3 = CNN_Architecture(numFilters = numFilters2,\n",
    "                                    filterSize = (3, 3), \n",
    "                                    strides = 1, \n",
    "                                    toPadding = True, \n",
    "                                    useReLU = True, \n",
    "                                    numInputChannels = numFilters3, \n",
    "                                    maxPoolingSize=(2, 2))\n",
    "\n",
    "# Convolution Layer 4\n",
    "cnnArchitecture4 = CNN_Architecture(numFilters = numFilters4,\n",
    "                                    filterSize = (3, 3), \n",
    "                                    strides = 1, \n",
    "                                    toPadding = True, \n",
    "                                    useReLU = True, \n",
    "                                    numInputChannels = numFilters3, \n",
    "                                    maxPoolingSize=(2, 2))\n",
    "dcnnArchitecture4 = CNN_Architecture(numFilters = numFilters3,\n",
    "                                    filterSize = (3, 3), \n",
    "                                    strides = 1, \n",
    "                                    toPadding = True, \n",
    "                                    useReLU = True, \n",
    "                                    numInputChannels = numFilters4, \n",
    "                                    maxPoolingSize=(2, 2))\n",
    "\n",
    "# Fully Connected 1\n",
    "fc5_size = 1024 \n",
    "\n",
    "# Lattern Code \n",
    "z_dim = 256\n",
    "\n",
    "# flattern size\n",
    "flat_size = 4096"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class Image:\n",
    "    size = 64\n",
    "    channels = 3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div>\n",
    "<h1>Network Output Size</h1>\n",
    "    <p>\n",
    "    <ul>\n",
    "        <li>Input Layer: 64 * 64 * 3 = 12288</li>\n",
    "        <li>Convolutional Layer1: 32 * 32 * 32 = 32768 </li>\n",
    "        <li>Convolutional Layer2: 16 * 16 * 64 = 16384 </li>\n",
    "        <li>Convolutional Layer3: 8 * 8 * 128 = 8192 </li>\n",
    "        <li>Convolutional Layer4: 4 * 4 * 256 = 4096 </li>\n",
    "        <li>Fully Connected Layer5: 1024 </li>\n",
    "        <li>Latten Code: 256 </li>\n",
    "    </ul>\n",
    "    </p>\n",
    "</div>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "class DCGAN:\n",
    "    \"\"\"\n",
    "    \"\"\"\n",
    "    def __init__(self, batch_size, lr_g=1e-3, lr_d=1e-4):\n",
    "        self.lr_g = lr_g\n",
    "        self.lr_d = lr_d\n",
    "        self.batch_size = batch_size\n",
    "        self.sess = tf.Session()\n",
    "        \n",
    "        self.build_model()\n",
    "        \n",
    "    def build_model(self):\n",
    "        # ---------- 1. placeholder ----------\n",
    "        self.lattenCode = tf.placeholder(tf.float32, shape = [None, z_dim])\n",
    "        self.inputImages = tf.placeholder(tf.float32, shape = [None, Image.size, Image.size, Image.channels])\n",
    "        \n",
    "        # ---------- 2. Discriminator & generator ----------\n",
    "        self.discriminate_true = self.build_discriminator(self.inputImages, is_training = True, \n",
    "                                                          reuse = False, init_stdev = 0.01)\n",
    "        \n",
    "        self.generatedImgs = self.build_generator(self.lattenCode, is_training = True, bs = self.batch_size, \n",
    "                                                  reuse = False, init_stdev = 0.01)\n",
    "        \n",
    "        self.dicriminate_fake = self.build_discriminator(self.generatedImgs, is_training = True, \n",
    "                                                         reuse = True, init_stdev = 0.01)\n",
    "        # ---------- 3. Cost Function & Optimizer ----------\n",
    "        # Discriminator loss \n",
    "        discriminator_true_loss = tf.log(self.discriminate_true)\n",
    "        discriminator_fake_loss = tf.log(1 - self.dicriminate_fake)\n",
    "#         discriminator_fake_loss = -tf.log(self.dicriminate_fake)\n",
    "        \n",
    "        discriminator_reward = tf.reduce_mean(discriminator_true_loss + discriminator_fake_loss)\n",
    "        self.discriminator_loss = -1.0 * discriminator_reward\n",
    "        \n",
    "        # Generator Loss \n",
    "#         self.generator_loss = tf.reduce_mean(discriminator_fake_loss)\n",
    "        self.generator_loss = tf.reduce_mean(-tf.log(self.dicriminate_fake))\n",
    "        \n",
    "        # Optimizer \n",
    "        all_vars = tf.trainable_variables()\n",
    "        d_vars = [var for var in all_vars if 'discriminator' in var.name]\n",
    "        g_vars = [var for var in all_vars if 'generator' in var.name]\n",
    "        \n",
    "        ## For Testing\n",
    "#         d_names = [v.name for v in d_vars]\n",
    "#         g_names = [v.name for v in g_vars]\n",
    "#         print('d_names:', d_names)\n",
    "#         print('g_names', g_names)\n",
    "        \n",
    "        self.generator_optimizer = tf.train.AdamOptimizer(self.lr_g).minimize(self.generator_loss, var_list=g_vars)\n",
    "        self.discriminator_optimizer = tf.train.AdamOptimizer(self.lr_d).minimize(self.discriminator_loss, var_list=d_vars)\n",
    "        \n",
    "        # ---------- 4. build Testing Model ----------\n",
    "        self.numGenerates = 100\n",
    "        self.fake_images = self.build_generator(self.lattenCode, is_training = False, reuse = True, \n",
    "                                                bs = self.numGenerates, init_stdev = 0.01)\n",
    "            \n",
    "    def build_discriminator(self, inputLayer, is_training = True, reuse = False, init_stdev = 0.01):\n",
    "        \"\"\"\n",
    "        Arg:\n",
    "        -------------------------------------------------------------------------\n",
    "          * inputLayer [tensor] shape = (batch, height, width, channel).\n",
    "          \n",
    "        \"\"\"\n",
    "        with tf.variable_scope(\"discriminator\", reuse = reuse):\n",
    "            # Convolutional Layers\n",
    "            conv1, _ = new_convLayer(inputLayer, cnnArchitecture1, name = \"dis_conv1\", stdev = init_stdev)\n",
    "            conv2, _ = new_convLayer(conv1, cnnArchitecture2, name = \"dis_conv2\", stdev = init_stdev)\n",
    "            conv2 = bn(conv2, is_training = is_training, scope = \"dis_bn2\")\n",
    "            conv3, _ = new_convLayer(conv2, cnnArchitecture3, name = \"dis_conv3\", stdev = init_stdev)\n",
    "            conv3 = bn(conv3, is_training = is_training, scope = \"dis_bn3\")\n",
    "            conv4, _ = new_convLayer(conv3, cnnArchitecture4, name = \"dis_conv4\", stdev = init_stdev)\n",
    "            conv4 = bn(conv4, is_training = is_training, scope = \"dis_bn4\")\n",
    "            \n",
    "#             ## for testing\n",
    "#             _, nodes1 = flattenLayer(conv1)\n",
    "#             _, nodes2 = flattenLayer(conv2)\n",
    "#             _, nodes3 = flattenLayer(conv3)\n",
    "#             _, nodes4 = flattenLayer(conv4)\n",
    "#             nodess = [nodes1, nodes2, nodes3, nodes4]\n",
    "#             for i in range(1, 5): \n",
    "#                 print('#nodes in conv{}: {}'.format(i, nodess[i - 1]))\n",
    "            \n",
    "            # Flattern\n",
    "            flat, numNodes = flattenLayer(conv4)\n",
    "#             assert numNodes == flat_size, \"Something wrong while flatterning ... {} != {}\".format(numNodes, flat_size)\n",
    "            self.flat_size = numNodes\n",
    "            \n",
    "            # Fully Connected Layers\n",
    "            fc5 = new_fcLayer(flat, numNodes, fc5_size, useReLU=True, name=\"dis_fc5\", stdev=init_stdev)\n",
    "            fc5 = bn(fc5, is_training = is_training, scope = \"dis_bn5\")\n",
    "            output = new_fcLayer(fc5, fc5_size, 1, useReLU=False, name=\"dis_out\", stdev=init_stdev)\n",
    "            output = tf.nn.sigmoid(output)\n",
    "            \n",
    "            return output\n",
    "            \n",
    "    \n",
    "    def build_generator(self, inputLayer, is_training = True, bs = None, reuse = False, init_stdev = 0.01):\n",
    "        if bs is None:\n",
    "            bs = self.batch_size\n",
    "            \n",
    "        with tf.variable_scope(\"generator\", reuse = reuse):\n",
    "            # de fully connected layers\n",
    "            fc1 = new_fcLayer(inputLayer, z_dim, fc5_size, useReLU=True, name=\"gen_fc1\", stdev=init_stdev)\n",
    "            fc1 = bn(fc1, is_training = is_training, scope = \"gen_bn1\")\n",
    "            fc2 = new_fcLayer(fc1, fc5_size, self.flat_size, useReLU=True, name=\"gen_dconv2\", stdev=init_stdev)\n",
    "            fc2 = bn(fc2, is_training = is_training, scope = \"gen_bn2\")\n",
    "            \n",
    "            # Reshaping\n",
    "            conv2 = tf.reshape(fc2, shape=[-1, 4, 4, numFilters4])\n",
    "            \n",
    "            # Convolutional Layers\n",
    "            conv2 = unpool(conv2, kernel=(2, 2))\n",
    "            conv3 = new_dconvLayer(conv2, dcnnArchitecture4, outputShape = [bs, 8, 8, 128], \n",
    "                                   name = \"gen_dconv3\", stdev = init_stdev)\n",
    "            conv3 = bn(conv3, is_training = is_training, scope = \"gen_bn3\")\n",
    "            \n",
    "            conv3 = unpool(conv3, kernel=(2, 2))\n",
    "            conv4 = new_dconvLayer(conv3, dcnnArchitecture3, outputShape = [bs, 16, 16, 64], \n",
    "                                   name = \"gen_dconv4\", stdev = init_stdev)\n",
    "            conv4 = bn(conv4, is_training = is_training, scope = \"gen_bn4\")\n",
    "            \n",
    "            conv4 = unpool(conv4, kernel=(2, 2))\n",
    "            conv5 = new_dconvLayer(conv4, dcnnArchitecture2, outputShape = [bs, 32, 32, 32], \n",
    "                                   name = \"gen_dconv5\", stdev = init_stdev)\n",
    "            conv5 = bn(conv5, is_training = is_training, scope = \"gen_bn5\")\n",
    "            \n",
    "            conv5 = unpool(conv5, kernel=(2, 2))\n",
    "            image = new_dconvLayer(conv5, dcnnArchitecture1, outputShape = [bs, Image.size, Image.size, Image.channels], \n",
    "                                   name = \"gen_image\", stdev = init_stdev)\n",
    "            image = tf.nn.sigmoid(image)\n",
    "            \n",
    "            return image\n",
    "            \n",
    "            \n",
    "    def train(self, fileDir, epochs = 100, saveModel = False, k = 1):\n",
    "        generator_lossHistory = []\n",
    "        discriminator_lossHistory = []\n",
    "        \n",
    "        print('  * Start Training ...')\n",
    "        self.sess.run(tf.global_variables_initializer())\n",
    "        half_batch = self.batch_size // 2\n",
    "        for epoch in range(epochs):\n",
    "            print('  * processing epoch #{} '.format(epoch))\n",
    "            count = 0\n",
    "            for batch in readImagesIn(directory=fileDir, size=(Image.size, Image.size),\n",
    "                                           noiseStdev=0.0, batch_size = (self.batch_size)*k ):\n",
    "                count += 1\n",
    "                # ----------- Train Discriminator k times ----------\n",
    "                for i in range(k):\n",
    "                    batch_imgs = batch[i*self.batch_size :(i+1)*self.batch_size]\n",
    "                    batch_z = np.random.normal(0, 1, [self.batch_size, z_dim])\n",
    "                    \n",
    "                    feed_dict_discriminator = {self.lattenCode : batch_z, self.inputImages : batch_imgs}  \n",
    "\n",
    "                    _, d_loss = self.sess.run([self.discriminator_optimizer, self.discriminator_loss],\n",
    "                                               feed_dict = feed_dict_discriminator)\n",
    "                # append loss every k times => ez to plot\n",
    "                discriminator_lossHistory.append(d_loss)\n",
    "                \n",
    "                # ---------- Train Generator 1 time ----------\n",
    "                batch_z = np.random.normal(0, 1, [self.batch_size, z_dim])\n",
    "                feed_dict_generator = {self.lattenCode : batch_z}\n",
    "                \n",
    "                _, g_loss = self.sess.run([self.generator_optimizer, self.generator_loss], \n",
    "                                          feed_dict = feed_dict_generator)\n",
    "                generator_lossHistory.append(g_loss)\n",
    "                \n",
    "                \n",
    "                # ---------- Print Loss every t times ----------\n",
    "                if count % 250 == 1:\n",
    "                    print('\\tepoch #{} , iterations #{}, g_loss = {}, d_loss = {}'.format(epoch, count, g_loss, d_loss))\n",
    "                    \n",
    "            print('\\tDONE!  g_loss = {}, d_loss = {}'.format(g_loss, d_loss))\n",
    "                \n",
    "        \n",
    "        ## TODO...\n",
    "        # Dst tensor is not initialized Error while saving model\n",
    "        if saveModel:\n",
    "            saver = tf.train.Saver()\n",
    "            save_path = saver.save(self.sess, \"../models/DCGAN/dcgan.ckpt\")\n",
    "            print(\"  * Model saved in path: %s\" % save_path)\n",
    "        # -------- Plot Learning Curve --------\n",
    "        plt.figure()\n",
    "        plt.title('Learning Curve')\n",
    "        plt.xlabel('# Iterations')\n",
    "        plt.ylabel('Cost')\n",
    "        plt.plot(discriminator_lossHistory, label=\"Discriminator\")\n",
    "        plt.plot(generator_lossHistory, label=\"Generator\")\n",
    "        plt.legend(loc = 'best')\n",
    "        plt.savefig('../figure/DCGAN/LearningCurve.png')\n",
    "        \n",
    "    def save(self, path):\n",
    "        raise NotImplementedError\n",
    "        \n",
    "    def load(self, path):\n",
    "        raise NotImplementedError\n",
    "        \n",
    "    def generateFakeImages(self, numImgs):\n",
    "        z = np.random.normal(0, 1, size=(self.numGenerates, z_dim))\n",
    "        feed_dict_test = {self.lattenCode : z }\n",
    "        fakeImg = self.sess.run(self.fake_images, feed_dict=feed_dict_test)\n",
    "        return fakeImg\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  * Building Model ..."
     ]
    }
   ],
   "source": [
    "if __name__ == '__main__':\n",
    "    directory = '../data/'\n",
    "#     directory = '../faces/'\n",
    "    batch_size = 128\n",
    "    \n",
    "    print('  * Building Model ...', end=\"\")\n",
    "    dc_gan = DCGAN(batch_size = batch_size, lr_g=1e-3, lr_d=1e-4)\n",
    "    print('  Finished!!')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## Thing to do \n",
    "# 1. Add noise to input of discriminator, decay as time increasing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "dc_gan.train(fileDir=directory, epochs = 100, saveModel = False, k = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#\n",
    "## ---------- Fake Images ----------\n",
    "#\n",
    "\n",
    "\n",
    "# z = np.random.normal(0, 5, size=(batch_size, z_dim))\n",
    "# # z = np.random.uniform(-5, 5, size=(batch_size, z_dim))\n",
    "# feed_dict_test = {vae.lattenCode : z }\n",
    "# imgs = vae.sess.run(vae.fake_images, feed_dict=feed_dict_test)\n",
    "imgs = dc_gan.generateFakeImages(dc_gan.numGenerates)\n",
    "plotImages(imgs, savePath = '../figure/DCGAN/generate.png')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [tensorflow-gpu]",
   "language": "python",
   "name": "Python [tensorflow-gpu]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
